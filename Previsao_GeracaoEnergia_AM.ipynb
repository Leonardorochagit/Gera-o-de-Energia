{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Previsao_GeracaoEnergia_AM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "VkffcBAncf48",
        "uYj_5sC6ckOG"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2Xz7wNWya+SPhGV0Zpr9K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonardorochagit/Geracao_Energia/blob/main/Previsao_GeracaoEnergia_AM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center>Universidade do Estado do Amazonas</center>\n",
        "###  <center>Escola Superior de Tecnologia</center>\n",
        "#####  <center>Pós-graduação Lato Sensu em Ciência de Dados</center>\n",
        "#####  <center>Programação para Ciência de Dados (Turma 02)</center>\n",
        "---\n",
        "## <center>TCC de Conclusão de Curso </center>\n",
        "## <center> Previsão de Geração de Energia: Amazonas </center>\n"
      ],
      "metadata": {
        "id": "-6VvrbCzbT3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Importação das Bibliotecas e Configurações Ambiente**\n",
        "\n"
      ],
      "metadata": {
        "id": "VkffcBAncf48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sweetviz -q\n",
        "# !pip install -U pandas-profiling\n",
        "# !pip install --user -q datascience"
      ],
      "metadata": {
        "id": "_ZRRh-Ih8Nmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -q pandas -plotting"
      ],
      "metadata": {
        "id": "1bG7b_0PnhHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Leonardorochagit/Geracao_Energia\n",
        "#! git clone https://github.com/paulordie/sentimental_ds\n",
        "%cd Geracao_Energia/Base_ONS/"
      ],
      "metadata": {
        "id": "mlKx1_RnamSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "lQ-GbfU0cHHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "oUovrC61196g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# palette -> Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, icefire, icefire_r, inferno, inferno_r, jet, jet_r, magma, magma_r, mako, mako_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, rocket, rocket_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, vlag, vlag_r, winter, winter_r\n",
        "sns.set_palette(\"Blues_r\")\n",
        "\n",
        "# style -> white, dark, whitegrid, darkgrid, ticks\n",
        "sns.set_style(\"darkgrid\")"
      ],
      "metadata": {
        "id": "_TrgmzXScHKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "unh8vhYocHNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Abrindo a Base de Dados** "
      ],
      "metadata": {
        "id": "uYj_5sC6ckOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset em um dataframe com Pandas\n",
        "df = pd.read_csv('/content/Geracao_Energia/Base_ONS/4. Simples_Geração_de_Energia_Dia_data AMAZONAS.csv', sep = ';', \n",
        "                 index_col=0, header=0, parse_dates=True, squeeze=True) # header=0, index_col=0, parse_dates=True, squeeze=True\n",
        "df.head()    "
      ],
      "metadata": {
        "id": "__yernu2dO-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "N0ztiW35dPLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_colunas_drop = ['cod_aneel (tb_referenciacegusina (Usina))', 'cod_nucleoaneel (tb_referenciacegusina (Usina))', \n",
        "                      'Data Dica','dsc_estado', 'id_subsistema', 'nom_tipousinasite', 'nom_usina2', \n",
        "                      'Período Exibido GE']\n",
        "df=df.drop(columns=lista_colunas_drop)\n",
        "df"
      ],
      "metadata": {
        "id": "CMbafAJT4csP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'Data Escala de Tempo 1 GE Simp 4':'Data/Hora','Selecione Tipo de GE Simp 4':'Geracao_(GWh)'})\n",
        "#df = df.reset_index(drop=True)\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "wNlWhUfe7Y8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index.names = ['Data/Hora']\n",
        "df"
      ],
      "metadata": {
        "id": "grtONEkR_8dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Geracao_(GWh)']=df['Geracao_(GWh)'].apply(lambda x: str(x).replace(',','.'))\n",
        "df"
      ],
      "metadata": {
        "id": "bJcv05IB2ZGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Geracao_(GWh)']=df['Geracao_(GWh)'].astype('float64')"
      ],
      "metadata": {
        "id": "Zf8zIIB26L9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "CvehzW6Q51Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "4atePffrBpRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "id": "YjTGohcWKiZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['year'] = df.index.year\n",
        "df['month']  = df.index.month\n",
        "df['weekday'] = df.index.weekday\n",
        "df['weekofyear'] = df.index.weekofyear\n",
        "df['quarter'] = df.index.quarter\n",
        "df.tail(3)"
      ],
      "metadata": {
        "id": "F1WsasyoNhQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Manipulando a Base de Dados** "
      ],
      "metadata": {
        "id": "QyMIhsA4iA-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Geracao_(GWh)'].plot()"
      ],
      "metadata": {
        "id": "HRQ-nE7oj8RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "gpNdO2qZSZPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.iloc[:,0:1]"
      ],
      "metadata": {
        "id": "ViF-XB4aSv80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "QOtxG__2SyjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "NTw02Md3S6eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping data based on month and store type\n",
        "dfbox= df1.groupby([pd.Grouper(freq='A'), 'Geracao_(GWh)']).sum().head(15)"
      ],
      "metadata": {
        "id": "ueXupD2VPnIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfbox.head(30)"
      ],
      "metadata": {
        "id": "KhQOwxR8UfQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pandas import DataFrame\n",
        "# years=DataFrame()\n",
        "# for name, group in df1: \n",
        "#    years[name.year]=group.values\n",
        "# years.boxplot\n",
        "# pyplot.show()"
      ],
      "metadata": {
        "id": "N9JVuY6gYDxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.date_range('2008-01-01', '2022-01-10', freq='M')"
      ],
      "metadata": {
        "id": "qe1o9WR5aluB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the data columns we want to include (i.e. exclude Year, Month, Weekday Name)\n",
        "data_columns = ['Geracao_(GWh)']\n",
        "# Resample to weekly frequency, aggregating with mean\n",
        "df_ano = df1[data_columns].resample('Y').sum()\n",
        "df_ano.head(15)"
      ],
      "metadata": {
        "id": "pT9-36Zwbbce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = DataFrame()\n",
        "for name, group in groups:\n",
        "\tyears[name.year] = group.values\n",
        "years.boxplot()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "IOhTJIdtc8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ano['Geracao_(GWh)'].plot()"
      ],
      "metadata": {
        "id": "pxZmAn5hbvkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ano"
      ],
      "metadata": {
        "id": "FkLWTcSSjTfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.df_ano(x=df_ano.index, y='Geracao_(GWh)', data=df_ano)"
      ],
      "metadata": {
        "id": "jW1HTlO4il6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = df1, index=pd.date_range(start=\"2013-01-01\", periods=n, freq=\"Y\"))\n",
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "seaborn.boxplot(ts.index.dayofyear, ts, ax=ax)"
      ],
      "metadata": {
        "id": "C8QgpEjHdLgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import Grouper\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "nCqnMUjfdtAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups = df1.groupby(Grouper(freq='A'))\n",
        "groups.head()"
      ],
      "metadata": {
        "id": "DU3n8p2IeD1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GaulRYf8Uddo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Try lag 1 day\n",
        "pd.plotting.lag_plot(df['Geracao_(GWh)'], lag =24 )"
      ],
      "metadata": {
        "id": "BejyyBltkWmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Try lag 365 day\n",
        "pd.plotting.lag_plot(df['Geracao_(GWh)'], lag = 8640)"
      ],
      "metadata": {
        "id": "0jCQrerpkhC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-correlation Plots"
      ],
      "metadata": {
        "id": "eJjYO4T1laOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import autocorrelation_plot"
      ],
      "metadata": {
        "id": "WNXx0jColYBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autocorrelation_plot(df)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "E8_OKtiboPQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "plot_acf(df, lags=31)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "YoIpCSgQoVk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partial Auto-Correlation"
      ],
      "metadata": {
        "id": "5QweXsFUobET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "plot_pacf(df, lags=50)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "DzPtrop6oeIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F9znn8ivmrp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Normalizando** #"
      ],
      "metadata": {
        "id": "FQXLGwa_nM8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from keras.layers import Dense,Dropout,SimpleRNN,LSTM\n",
        "from keras.models import Sequential\n",
        "\n",
        "#check all the files in the input dataset\n",
        "#print(os.listdir(\"../input/\"))"
      ],
      "metadata": {
        "id": "Hyocm4b-nXg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "dHbozaTgn0L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = df.copy() # make temporary copy of dataframe\n",
        "dataset = temp['Geracao_(GWh)'].values # numpy.ndarray of the actual load\n",
        "dataset = dataset.astype('float32') \n",
        "dataset = np.reshape(dataset, (-1, 1)) # reshape to one feature; required for the models\n",
        "\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1)) # Min Max scaler\n",
        "#dataset = scaler.fit_transform(dataset) # fit and transform the dataset\n",
        "\n",
        "# Train and Test splits\n",
        "train_size = int(len(dataset) * 0.80) \n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "    \n",
        "look_back = 25 # timesteps to lookback for predictions\n",
        "X_train, trainY = create_dataset(train, look_back)\n",
        "X_test, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "print(\"Shapes: \\nTraining set: {}, Testing set: {}\".format(X_train.shape, X_test.shape))\n",
        "print(\"Sample from training set: \\n{}\".format(X_train[0]))"
      ],
      "metadata": {
        "id": "bkhuftndrSAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Models and their MAPE\n",
        "Here we test various models and visualize their predictions. Models used are:\n",
        "\n",
        "AutoRegressive\n",
        "Moving Average\n",
        "ARMA\n",
        "ARIMA\n",
        "LSTM"
      ],
      "metadata": {
        "id": "kYLzhOYRrvu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dalV6253rsDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.ar_model import AR\n",
        "\n",
        "model = AR(train)\n",
        "model_fit = model.fit()"
      ],
      "metadata": {
        "id": "u9U5p53Droxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mt7cXb1uuG6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM"
      ],
      "metadata": {
        "id": "HGVRyHcnsyy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\", font_scale=1.3)\n",
        "sns.set_style('white')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from time import time\n",
        "import matplotlib.ticker as tkr\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn import preprocessing\n",
        "from statsmodels.tsa.stattools import pacf\n",
        "%matplotlib inline\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "metadata": {
        "id": "zZqRKx-6uHsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = df\n",
        "dataset = temp['Geracao_(GWh)'].dropna().values #numpy.ndarray\n",
        "dataset = dataset.astype('float32')\n",
        "dataset = np.reshape(dataset, (-1, 1))\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) # Min Max scaler\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "train_size = int(len(dataset) * 0.80)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        X.append(a)\n",
        "        Y.append(dataset[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "    \n",
        "look_back = 25\n",
        "X_train, Y_train = create_dataset(train, look_back)\n",
        "X_test, Y_test = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "2AWZgHOCs376"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=200, batch_size=70, validation_data=(X_test, Y_test),verbose=1, shuffle=False)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xCnTXYUnuRFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "# invert predictions\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "Y_train = scaler.inverse_transform([Y_train])\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "Y_test = scaler.inverse_transform([Y_test])\n",
        "print('Train Mean Absolute Error:', mean_absolute_error(Y_train[0], train_predict[:,0]))\n",
        "print('Train Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0])))\n",
        "print('Test Mean Absolute Error:', mean_absolute_error(Y_test[0], test_predict[:,0]))\n",
        "print('Test Root Mean Squared Error:',np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0])))"
      ],
      "metadata": {
        "id": "QN7K_n1vuU8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape_train = np.mean(np.abs((Y_train[0] - train_predict[:,0]) / Y_train[0])) * 100\n",
        "mape_test = np.mean(np.abs((Y_test[0] - test_predict[:,0]) / Y_test[0])) * 100\n",
        "\n",
        "print(\"Train MAPE: {}, Test MAPE: {}\".format(mape_train, mape_test))"
      ],
      "metadata": {
        "id": "-N4fQK6PuXyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Test Loss')\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "4Rt3FTGUug0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 200\n",
        "aa=[x for x in range(idx)]\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(aa, Y_test[0][:idx], marker='.', label=\"actual\")\n",
        "plt.plot(aa, test_predict[:,0][:idx], 'r', label=\"prediction\")\n",
        "# plt.tick_params(left=False, labelleft=True) #remove ticks\n",
        "plt.tight_layout()\n",
        "sns.despine(top=True)\n",
        "plt.subplots_adjust(left=0.07)\n",
        "plt.ylabel('TOTAL Load', size=15)\n",
        "plt.xlabel('Time step', size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "4SDvODZLujNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}